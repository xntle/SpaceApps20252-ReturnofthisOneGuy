# ðŸŽ“ Complete Training Guide - Enhanced Multimodal Exoplanet Detection

This guide provides step-by-step instructions for training the enhanced multimodal exoplanet detection model from scratch.

## ðŸ“‹ Prerequisites

### System Requirements
- Python 3.11+
- 8GB+ RAM (16GB recommended)
- 10GB+ disk space for data and models
- Internet connection for downloading Kepler data

### Environment Setup
```bash
# Clone the repository
git clone https://github.com/Shyam-723/NasaExoSkyChallenge.git
cd NasaExoSkyChallenge

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

## ðŸš€ Quick Start (Pre-trained Model)

If you want to use the pre-trained model immediately:

```bash
# Download pre-trained model (if not included)
# The repository includes: models/enhanced_multimodal_fusion_model.pth

# Test the pre-trained model
python demo_inference.py --kepid 10797460

# Or run batch predictions
python demo_inference.py --batch-predict --num-samples 10
```

## ðŸ”„ Full Training Pipeline

### Step 1: Data Preparation

#### 1.1 Download Raw Data
```bash
# The repository includes the enriched KOI dataset
# If you need to re-download or update:
python scripts/enrich_koi.py
```

#### 1.2 Generate CNN Data (Time-Intensive)
```bash
# Generate CNN data for 200 targets (takes ~4.5 hours)
python scripts/rapid_cnn_expansion.py --max-targets 200 --max-time 270

# For faster testing (50 targets, ~1 hour):
python scripts/rapid_cnn_expansion.py --max-targets 50 --max-time 60

# For maximum coverage (500+ targets, ~12 hours):
python scripts/rapid_cnn_expansion.py --max-targets 500 --max-time 720
```

Expected output:
```
ðŸš€ RAPID CNN DATA EXPANSION PIPELINE
====================================
ðŸŽ¯ Target: 200 max targets, 270 minute limit
ðŸ“Š Starting with 81 residual windows, 58 pixel differences

[Processing progress...]

âœ… EXPANSION COMPLETE!
ðŸ“Š Final counts:
   Residual windows: 243 files (+162)
   Pixel differences: 134 files (+76)
   Total coverage: 2.5% (377/9777 targets)
```

#### 1.3 Standardize CNN Data
```bash
# Standardize the generated CNN data
python scripts/standardize_cnn_data.py
```

Expected output:
```
ðŸ”§ CNN DATA STANDARDIZATION PIPELINE
===================================
ðŸ“Š Standardizing residual windows...
   Processed: 243 files
   Shape: (243, 128) -> saved to residual_windows_std/

ðŸ“Š Standardizing pixel differences...  
   Processed: 134 files
   Shape: (134, 32, 24, 24) -> saved to pixel_diffs_std/

âœ… Standardization complete!
```

### Step 2: Train the Enhanced Model

```bash
# Train the enhanced multimodal fusion model
python train_multimodal_enhanced.py
```

Expected training output:
```
ðŸŒŸ ENHANCED MULTI-MODAL EXOPLANET DETECTION PIPELINE
=================================================================

ðŸ“Š Dataset loaded: 9777 total samples
ðŸ“Š Filtered to confirmed/false positive: 2329 samples  
ðŸ“Š CNN coverage: 240 samples (2.5%)

ðŸ“Š Data splits:
   Training samples: 462
   Validation samples: 245
   Test samples: 98

ðŸš€ Training enhanced multimodal fusion model...

Epoch   1: Loss=0.6045, Val AUC=0.8204, Val Acc=0.8204, Time=1.2s
Epoch   5: Loss=0.4123, Val AUC=0.9102, Val Acc=0.8653, Time=5.8s
Epoch  10: Loss=0.2945, Val AUC=0.9387, Val Acc=0.9020, Time=10.4s
Epoch  20: Loss=0.1876, Val AUC=0.9591, Val Acc=0.9184, Time=21.1s
Epoch  30: Loss=0.1234, Val AUC=0.9683, Val Acc=0.9347, Time=31.8s
Epoch  45: Loss=0.0840, Val AUC=0.9683, Val Acc=0.9347, Time=54.6s

ðŸ›‘ Early stopping at epoch 45 (patience=20)
âœ… Training complete! Best validation AUC: 0.9751

ðŸ† ENHANCED MULTI-MODAL RESULTS
ðŸŽ¯ Test Accuracy: 90.20%
ðŸŽ¯ Validation Accuracy: 93.47%
ðŸŽ¯ Test AUC: 97.41%
ðŸŽ¯ Optimal Threshold: 0.9922 (TPR: 88.56%, FPR: 4.55%)

ðŸ’¾ Enhanced model saved to models/enhanced_multimodal_fusion_model.pth
```

### Step 3: Evaluate the Model

```bash
# Test the trained model
python demo_inference.py --batch-predict --num-samples 20
```

## âš™ï¸ Training Configuration

### Default Training Parameters
```python
# Training configuration
BATCH_SIZE = 32
LEARNING_RATE = 0.001
EARLY_STOPPING_PATIENCE = 20
MAX_EPOCHS = 100

# Data splits
TRAIN_RATIO = 0.6
VAL_RATIO = 0.2  
TEST_RATIO = 0.2

# Model architecture
TABULAR_DIM = 39
RESIDUAL_LENGTH = 128
PIXEL_SHAPE = (32, 24, 24)
```

### Customizing Training
Edit `train_multimodal_enhanced.py` to modify:

```python
# Example modifications:
config = {
    'batch_size': 64,           # Larger batches (if you have more RAM)
    'learning_rate': 0.0005,    # Lower learning rate for stability
    'patience': 30,             # More patience for early stopping
    'max_epochs': 150,          # More training epochs
}
```

## ðŸ“ˆ Data Coverage Scaling

### Coverage vs Performance
| CNN Coverage | Files | Expected Val Accuracy | Training Time |
|--------------|-------|----------------------|---------------|
| 0.7% | 70 | 88-89% | 30 seconds |
| 2.5% | 240 | 93-94% | 55 seconds |
| 5.0% | 500 | 95-96% | 2-3 minutes |
| 10.0% | 1000 | 96-97% | 5-6 minutes |

### Scaling Strategy
```bash
# For research/development (fast iteration)
python scripts/rapid_cnn_expansion.py --max-targets 100 --max-time 120

# For production model (optimal balance)
python scripts/rapid_cnn_expansion.py --max-targets 200 --max-time 270

# For maximum performance (overnight training)
python scripts/rapid_cnn_expansion.py --max-targets 500 --max-time 720
```

## ðŸ› Troubleshooting

### Common Issues

#### 1. MAST Download Failures
```bash
# Error: HTTPSConnectionPool timeout
# Solution: Retry the CNN expansion (it resumes automatically)
python scripts/rapid_cnn_expansion.py --max-targets 200 --max-time 270
```

#### 2. Missing Dependencies
```bash
# Error: No module named 'lightkurve'
# Solution: Reinstall requirements
pip install -r requirements.txt
```

#### 3. CUDA Issues
```bash
# Error: CUDA out of memory
# Solution: Reduce batch size in train_multimodal_enhanced.py
# Change: batch_size = 16  # from 32
```

#### 4. Low CNN Coverage
```bash
# Warning: Only 50 CNN samples generated
# Solution: Increase time limit or target count
python scripts/rapid_cnn_expansion.py --max-targets 300 --max-time 360
```

### Performance Debugging

#### Check Data Coverage
```bash
# Check current CNN coverage
echo "Residual windows: $(ls data/processed/residual_windows_std/*.npy 2>/dev/null | wc -l)"
echo "Pixel differences: $(ls data/processed/pixel_diffs_std/*.npy 2>/dev/null | wc -l)"
```

#### Validate Model Performance
```bash
# Test model on known samples
python demo_inference.py --kepid 10797460  # Known confirmed planet
python demo_inference.py --kepid 10666592  # Known false positive
```

## ðŸŽ¯ Expected Results

### Training Progress
- **Epoch 1-10**: Rapid learning (AUC 0.82 â†’ 0.94)
- **Epoch 10-30**: Fine-tuning (AUC 0.94 â†’ 0.97)
- **Epoch 30-45**: Convergence (AUC 0.97 â†’ 0.975)
- **Early stopping**: Prevents overfitting

### Final Performance Targets
- **Validation Accuracy**: 93-94%
- **Validation AUC**: 97-98%
- **Test Accuracy**: 90-91%
- **Training Time**: 1-2 minutes

### Model Characteristics
- **High Precision**: ~95% (few false alarms)
- **Good Recall**: ~89% (catches most real planets)
- **Balanced**: Works well on both confirmed and false positive targets
- **Robust**: Handles missing CNN data gracefully

## ðŸš€ Production Deployment

### Model Export
```python
# The trained model is automatically saved as:
models/enhanced_multimodal_fusion_model.pth

# To load in production:
import torch
from src.models import EnhancedMultiModalFusionModel

model = EnhancedMultiModalFusionModel(39, 128, (32, 24, 24))
model.load_state_dict(torch.load('models/enhanced_multimodal_fusion_model.pth'))
model.eval()
```

### Inference Pipeline
```python
# Use the demo_inference.py as a template
# Key components:
# 1. prepare_single_sample() - data preprocessing
# 2. make_prediction() - model inference
# 3. Threshold 0.9922 for optimal TPR/FPR balance
```

## ðŸ“š Next Steps

1. **Scale Up**: Generate more CNN data for even higher accuracy
2. **Deploy**: Integrate the model into a web service or API
3. **Optimize**: Experiment with different fusion architectures
4. **Extend**: Add TESS mission support
5. **Validate**: Test on external exoplanet datasets

---

**ðŸŽ‰ Congratulations! You now have a state-of-the-art exoplanet detection model achieving 93.47% validation accuracy!**